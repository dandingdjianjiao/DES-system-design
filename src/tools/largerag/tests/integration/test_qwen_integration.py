#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•é€šä¹‰åƒé—®é›†æˆ
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

def test_qwen_with_dashscope():
    """æµ‹è¯•ä½¿ç”¨DashScopeä¸“ç”¨åŒ…"""
    print("ğŸ” æµ‹è¯•DashScopeä¸“ç”¨åŒ…...")
    
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        print("âŒ APIå¯†é’¥æœªè®¾ç½®")
        return False
    
    try:
        from llama_index.llms.dashscope import DashScope
        
        # è®¾ç½®DashScope APIå¯†é’¥
        os.environ["DASHSCOPE_API_KEY"] = api_key
        
        # åˆ›å»ºDashScope LLMå®ä¾‹
        llm = DashScope(
            model_name="qwen-turbo",
            api_key=api_key,
            temperature=0.1,
            max_tokens=100
        )
        
        # æµ‹è¯•ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ
        test_prompt = "ä»€ä¹ˆæ˜¯æ·±å…±ç†”æº¶å‰‚ï¼Ÿ"
        print(f"ğŸ“ æµ‹è¯•æç¤º: {test_prompt}")
        
        response = llm.complete(test_prompt)
        print(f"âœ… DashScopeå“åº”æˆåŠŸ:")
        print(f"   å“åº”: {response.text[:100]}...")
        
        return True
        
    except ImportError:
        print("âš ï¸  DashScopeåŒ…æœªå®‰è£…")
        return False
    except Exception as e:
        print(f"âŒ DashScopeæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_qwen_with_openai_compatible():
    """æµ‹è¯•ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼"""
    print("\nğŸ” æµ‹è¯•OpenAIå…¼å®¹æ¨¡å¼...")
    
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    api_base = os.getenv('OPENAI_API_BASE')
    
    if not api_key:
        print("âŒ APIå¯†é’¥æœªè®¾ç½®")
        return False
    
    try:
        from llama_index.llms.openai import OpenAI
        
        # åˆ›å»ºOpenAIå…¼å®¹çš„LLMå®ä¾‹
        llm = OpenAI(
            model="qwen-turbo",
            api_key=api_key,
            api_base=api_base,
            temperature=0.1,
            max_tokens=100
        )
        
        # æµ‹è¯•ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ
        test_prompt = "ä»€ä¹ˆæ˜¯æ·±å…±ç†”æº¶å‰‚ï¼Ÿ"
        print(f"ğŸ“ æµ‹è¯•æç¤º: {test_prompt}")
        
        response = llm.complete(test_prompt)
        print(f"âœ… OpenAIå…¼å®¹æ¨¡å¼å“åº”æˆåŠŸ:")
        print(f"   å“åº”: {response.text[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ OpenAIå…¼å®¹æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” æµ‹è¯•é€šä¹‰åƒé—®é›†æˆæ–¹å¼...")
    print("=" * 50)
    
    # æµ‹è¯•DashScopeä¸“ç”¨åŒ…
    dashscope_ok = test_qwen_with_dashscope()
    
    # æµ‹è¯•OpenAIå…¼å®¹æ¨¡å¼
    openai_compatible_ok = test_qwen_with_openai_compatible()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"   DashScopeä¸“ç”¨åŒ…: {'âœ…' if dashscope_ok else 'âŒ'}")
    print(f"   OpenAIå…¼å®¹æ¨¡å¼: {'âœ…' if openai_compatible_ok else 'âŒ'}")
    
    if not dashscope_ok:
        print("\nğŸ’¡ å®‰è£…DashScopeåŒ…:")
        print("   pip install llama-index-llms-dashscope")
    
    return 0 if (dashscope_ok or openai_compatible_ok) else 1

if __name__ == "__main__":
    sys.exit(main())