#!/usr/bin/env python3
"""
æµ‹è¯•LargeRAGå·¥å…·åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

def test_llama_index_imports():
    """æµ‹è¯•LlamaIndexå¯¼å…¥"""
    print("ğŸ” æµ‹è¯•LlamaIndexæ ¸å¿ƒåŠŸèƒ½å¯¼å…¥...")
    
    try:
        from llama_index.core import Document, VectorStoreIndex
        from llama_index.core.node_parser import SimpleNodeParser
        from llama_index.embeddings.openai import OpenAIEmbedding
        from llama_index.llms.openai import OpenAI
        from llama_index.vector_stores.chroma import ChromaVectorStore
        
        print("âœ… LlamaIndexæ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ LlamaIndexå¯¼å…¥å¤±è´¥: {e}")
        return False

def test_chroma_basic():
    """æµ‹è¯•ChromaåŸºæœ¬åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•Chromaå‘é‡æ•°æ®åº“åŸºæœ¬åŠŸèƒ½...")
    
    try:
        import chromadb
        from chromadb.config import Settings
        
        # åˆ›å»ºä¸´æ—¶å†…å­˜æ•°æ®åº“è¿›è¡Œæµ‹è¯•
        client = chromadb.Client(Settings(
            is_persistent=False,
            anonymized_telemetry=False
        ))
        
        # åˆ›å»ºé›†åˆ
        collection = client.create_collection(
            name="test_collection",
            metadata={"description": "æµ‹è¯•é›†åˆ"}
        )
        
        # æ·»åŠ æµ‹è¯•æ–‡æ¡£
        collection.add(
            documents=["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£", "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£"],
            metadatas=[{"source": "test1"}, {"source": "test2"}],
            ids=["doc1", "doc2"]
        )
        
        # æŸ¥è¯¢æµ‹è¯•
        results = collection.query(
            query_texts=["æµ‹è¯•"],
            n_results=1
        )
        
        print("âœ… ChromaåŸºæœ¬åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        print(f"   æŸ¥è¯¢ç»“æœæ•°é‡: {len(results['documents'][0])}")
        return True
        
    except Exception as e:
        print(f"âŒ Chromaæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_document_processing():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æ–‡æ¡£å¤„ç†åŠŸèƒ½...")
    
    try:
        from llama_index.core import Document
        from llama_index.core.node_parser import SimpleNodeParser
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        documents = [
            Document(text="è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼ŒåŒ…å«ä¸€äº›ç¤ºä¾‹å†…å®¹ã€‚"),
            Document(text="è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºæµ‹è¯•æ–‡æ¡£å¤„ç†åŠŸèƒ½ã€‚"),
        ]
        
        # åˆ›å»ºèŠ‚ç‚¹è§£æå™¨
        parser = SimpleNodeParser.from_defaults(
            chunk_size=100,
            chunk_overlap=20
        )
        
        # è§£ææ–‡æ¡£ä¸ºèŠ‚ç‚¹
        nodes = parser.get_nodes_from_documents(documents)
        
        print("âœ… æ–‡æ¡£å¤„ç†åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        print(f"   åŸå§‹æ–‡æ¡£æ•°é‡: {len(documents)}")
        print(f"   è§£æèŠ‚ç‚¹æ•°é‡: {len(nodes)}")
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡æ¡£å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_openai_config():
    """æµ‹è¯•OpenAIé…ç½®ï¼ˆä¸å®é™…è°ƒç”¨APIï¼‰"""
    print("\nğŸ” æµ‹è¯•OpenAIé…ç½®...")
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        print("âš ï¸  OPENAI_API_KEYæœªè®¾ç½®ï¼Œè·³è¿‡OpenAIé…ç½®æµ‹è¯•")
        print("   è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®APIå¯†é’¥ä»¥å¯ç”¨å®Œæ•´åŠŸèƒ½")
        return True
    
    try:
        from llama_index.embeddings.openai import OpenAIEmbedding
        from llama_index.llms.openai import OpenAI
        
        # åˆ›å»ºåµŒå…¥æ¨¡å‹å®ä¾‹ï¼ˆä¸å®é™…è°ƒç”¨ï¼‰
        embedding = OpenAIEmbedding(
            model="text-embedding-ada-002",
            api_key=api_key
        )
        
        # åˆ›å»ºLLMå®ä¾‹ï¼ˆä¸å®é™…è°ƒç”¨ï¼‰
        llm = OpenAI(
            model="gpt-4",
            api_key=api_key,
            temperature=0.1
        )
        
        print("âœ… OpenAIé…ç½®æµ‹è¯•æˆåŠŸ")
        print(f"   åµŒå…¥æ¨¡å‹: {embedding.model_name}")
        print(f"   LLMæ¨¡å‹: {llm.model}")
        return True
        
    except Exception as e:
        print(f"âŒ OpenAIé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” æµ‹è¯•LargeRAGå·¥å…·åŸºæœ¬åŠŸèƒ½...")
    print("=" * 60)
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        test_llama_index_imports,
        test_chroma_basic,
        test_document_processing,
        test_openai_config,
    ]
    
    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            results.append(False)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœ:")
    
    test_names = [
        "LlamaIndexå¯¼å…¥",
        "ChromaåŸºæœ¬åŠŸèƒ½",
        "æ–‡æ¡£å¤„ç†",
        "OpenAIé…ç½®"
    ]
    
    success_count = 0
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {name}")
        if result:
            success_count += 1
    
    print(f"\nğŸ“ˆ æˆåŠŸç‡: {success_count}/{len(results)} ({success_count/len(results)*100:.1f}%)")
    
    if success_count == len(results):
        print("ğŸ‰ æ‰€æœ‰åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("âš ï¸  éƒ¨åˆ†åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–")
        return 1

if __name__ == "__main__":
    sys.exit(main())