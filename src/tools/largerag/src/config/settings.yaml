# LargeRAG工具配置文件
# 基于LlamaIndex的大规模文献RAG系统配置

# 文档处理配置
document_processing:
  chunk_size: 1000
  chunk_overlap: 200
  max_documents_per_batch: 100

# 嵌入模型配置
embedding:
  model: "text-embedding-v1"  # 使用DashScope支持的嵌入模型
  api_key_env: "OPENAI_API_KEY"  # 或者使用 DASHSCOPE_API_KEY
  api_base_env: "OPENAI_API_BASE"  # 可选：自定义API基础URL
  batch_size: 100
  max_retries: 3
  # 使用专用DashScope嵌入包
  use_dashscope: true

# 向量存储配置
vector_store:
  type: "chroma"
  persist_directory: "${PROJECT_ROOT}data/largerag/indexes/"
  collection_name: "des_literature"
  distance_metric: "cosine"

# 检索配置
retrieval:
  top_k: 10
  similarity_threshold: 0.7
  rerank_enabled: false
  rerank_top_k: 20

# LLM配置
llm:
  model: "qwen-turbo"  # 使用DashScope支持的模型名称
  api_key_env: "OPENAI_API_KEY"  # 或者使用 DASHSCOPE_API_KEY
  api_base_env: "OPENAI_API_BASE"  # 可选：自定义API基础URL
  temperature: 0.1
  max_tokens: 4000
  streaming: false
  # 使用专用DashScope集成包而不是OpenAI兼容模式
  use_dashscope: true

# 日志配置
logging:
  level: "INFO"
  file_path: "${PROJECT_ROOT}logs/largerag.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  max_file_size: "10MB"
  backup_count: 5

# 性能配置
performance:
  enable_caching: true
  cache_directory: "${PROJECT_ROOT}data/largerag/cache/"
  max_cache_size: "1GB"
  parallel_processing: true
  max_workers: 4

# 系统配置
system:
  data_directory: "${PROJECT_ROOT}data/largerag/"
  temp_directory: "${PROJECT_ROOT}data/largerag/temp/"
  enable_metrics: true
  metrics_file: "${PROJECT_ROOT}logs/largerag_metrics.json"