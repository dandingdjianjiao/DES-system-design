"""
LargeRAG æ€§èƒ½æµ‹è¯•è„šæœ¬
====================================

æµ‹è¯•å†…å®¹ï¼š
1. å¯¹ rag_performance_test æ–‡ä»¶å¤¹ä¸­çš„10ç¯‡æ–‡çŒ®å»ºç«‹ç´¢å¼•
2. ä½¿ç”¨ question.txt ä¸­çš„10ä¸ªé—®é¢˜æµ‹è¯•RAGæ€§èƒ½
3. è®°å½•æ¯ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€æ£€ç´¢æ€§èƒ½å’ŒLLMç”Ÿæˆè´¨é‡

è¿è¡Œæ–¹å¼ï¼š
    # åŸºæœ¬è¿è¡Œ
    python examples/performance_test/perf_test.py              # åŠ è½½å·²æœ‰ç´¢å¼•
    python examples/performance_test/perf_test.py --rebuild    # å¼ºåˆ¶é‡å»ºç´¢å¼•

    # æŸ¥çœ‹å¸®åŠ©
    python examples/performance_test/perf_test.py --help       # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‚æ•°

    # è¦†ç›–é…ç½®å‚æ•°ï¼ˆæµ‹è¯•ä¸åŒé…ç½®çš„æ€§èƒ½ï¼‰
    python examples/performance_test/perf_test.py --similarity-top-k 30 --rerank-top-n 15
    python examples/performance_test/perf_test.py --llm-model qwen-max --llm-temperature 0.2
    python examples/performance_test/perf_test.py --chunk-size 1024 --chunk-overlap 100
    python examples/performance_test/perf_test.py --no-rerank  # ç¦ç”¨ Reranker

å¯è¦†ç›–çš„é…ç½®å‚æ•°ï¼š
    æ£€ç´¢é…ç½®ï¼š
      --similarity-top-k N           å‘é‡æ£€ç´¢å¬å›æ•°é‡
      --rerank-top-n N               Reranker æœ€ç»ˆè¿”å›æ•°é‡
      --similarity-threshold F       å‘é‡æ£€ç´¢ç›¸ä¼¼åº¦é˜ˆå€¼ (0-1)
      --rerank-threshold F           Reranker åˆ†æ•°é˜ˆå€¼
      --no-rerank                    ç¦ç”¨ Reranker

    LLM é…ç½®ï¼š
      --llm-model MODEL              LLM æ¨¡å‹åç§°
      --llm-temperature F            LLM æ¸©åº¦å‚æ•° (0-1)
      --llm-max-tokens N             LLM æœ€å¤§ç”Ÿæˆ tokens

    æ–‡æ¡£å¤„ç†é…ç½®ï¼š
      --splitter-type TYPE           åˆ†å—ç­–ç•¥ (token/semantic/sentence)
      --chunk-size N                 æ–‡æ¡£åˆ†å—å¤§å°
      --chunk-overlap N              æ–‡æ¡£åˆ†å—é‡å å¤§å°
      --separator STR                åˆ†å—åˆ†éš”ç¬¦
      --aggregate-small-chunks       èšåˆJSONæ–‡ä»¶å†…çš„æ‰€æœ‰ç‰‡æ®µ
      --semantic-breakpoint-threshold F  è¯­ä¹‰æ–­ç‚¹é˜ˆå€¼ (0-1)
      --semantic-buffer-size N       è¯­ä¹‰ç¼“å†²åŒºå¤§å°

    å‘é‡å­˜å‚¨é…ç½®ï¼š
      --vector-store-type TYPE       å‘é‡å­˜å‚¨ç±»å‹
      --persist-directory PATH       æŒä¹…åŒ–ç›®å½•
      --collection-name NAME         é›†åˆåç§°
      --distance-metric METRIC       è·ç¦»åº¦é‡ (cosine/l2/ip)

æ•°æ®ç»“æ„ï¼š
    src/tools/largerag/data/rag_performance_test/
    â”œâ”€â”€ 1/ ... 10/  (10ç¯‡æ–‡çŒ®æ–‡ä»¶å¤¹)
    â””â”€â”€ question.txt (10ä¸ªæµ‹è¯•é—®é¢˜)
"""

import sys
import time
import json
import argparse
from pathlib import Path
from datetime import datetime
from dataclasses import asdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
# perf_test.py â†’ performance_test â†’ examples â†’ largerag â†’ tools â†’ src â†’ PROJECT_ROOT
project_root = Path(__file__).resolve().parents[5]  # å¾€ä¸Š5çº§
sys.path.insert(0, str(project_root))

from src.tools.largerag import LargeRAG
from src.tools.largerag.config.settings import SETTINGS


def print_section(title: str):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


def print_subsection(title: str):
    """æ‰“å°å­æ ‡é¢˜"""
    print(f"\n--- {title} ---")


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='LargeRAG æ€§èƒ½æµ‹è¯•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬è¿è¡Œ
  python perf_test.py

  # å¼ºåˆ¶é‡å»ºç´¢å¼•
  python perf_test.py --rebuild

  # ç¦ç”¨ç¼“å­˜ï¼ˆæµ‹è¯•é…ç½®å˜åŒ–æ—¶æ¨èï¼‰
  python perf_test.py --rebuild --no-cache

  # è¦†ç›–æ£€ç´¢é…ç½®
  python perf_test.py --similarity-top-k 30 --rerank-top-n 15
  python perf_test.py --similarity-threshold 0.7 --rerank-threshold 0.5

  # è¦†ç›– LLM é…ç½®
  python perf_test.py --llm-model qwen-max --llm-temperature 0.2

  # è¦†ç›–æ–‡æ¡£å¤„ç†é…ç½®
  python perf_test.py --chunk-size 1024 --chunk-overlap 100
  python perf_test.py --splitter-type semantic --semantic-breakpoint-threshold 0.6
  python perf_test.py --separator "\\n\\n\\n"
  python perf_test.py --aggregate-small-chunks  # èšåˆJSONç‰‡æ®µ

  # è¦†ç›–å‘é‡å­˜å‚¨é…ç½®
  python perf_test.py --collection-name test_collection --distance-metric l2
  python perf_test.py --persist-directory /path/to/db

  # ç»„åˆå¤šä¸ªå‚æ•°
  python perf_test.py --chunk-size 768 --similarity-top-k 50 --llm-temperature 0.15

  # ç¦ç”¨ Reranker
  python perf_test.py --no-rerank
        """
    )

    # åŸºæœ¬é€‰é¡¹
    parser.add_argument('--rebuild', action='store_true',
                       help='å¼ºåˆ¶é‡å»ºç´¢å¼•ï¼ˆå³ä½¿å·²å­˜åœ¨ï¼‰')
    parser.add_argument('--no-cache', action='store_true',
                       help='ç¦ç”¨ç¼“å­˜ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®é‡å»ºï¼‰')

    # æ£€ç´¢é…ç½®å‚æ•°
    retrieval_group = parser.add_argument_group('æ£€ç´¢é…ç½®å‚æ•°')
    retrieval_group.add_argument('--similarity-top-k', type=int, metavar='N',
                                help='å‘é‡æ£€ç´¢å¬å›æ•°é‡ï¼ˆé»˜è®¤: 20ï¼‰')
    retrieval_group.add_argument('--rerank-top-n', type=int, metavar='N',
                                help='Reranker æœ€ç»ˆè¿”å›æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰')
    retrieval_group.add_argument('--similarity-threshold', type=float, metavar='FLOAT',
                                help='å‘é‡æ£€ç´¢ç›¸ä¼¼åº¦é˜ˆå€¼ 0-1ï¼ˆ0=ç¦ç”¨ï¼Œé»˜è®¤: 0.8ï¼‰')
    retrieval_group.add_argument('--rerank-threshold', type=float, metavar='FLOAT',
                                help='Reranker åˆ†æ•°é˜ˆå€¼ï¼ˆ0=ç¦ç”¨ï¼Œé»˜è®¤: 0.0ï¼‰')

    # Reranker é…ç½®
    reranker_group = parser.add_argument_group('Reranker é…ç½®')
    reranker_group.add_argument('--no-rerank', action='store_true',
                               help='ç¦ç”¨ Rerankerï¼ˆé»˜è®¤å¯ç”¨ï¼‰')

    # LLM é…ç½®å‚æ•°
    llm_group = parser.add_argument_group('LLM é…ç½®å‚æ•°')
    llm_group.add_argument('--llm-model', type=str, metavar='MODEL',
                          help='LLM æ¨¡å‹åç§°ï¼ˆé»˜è®¤: qwen-plusï¼‰')
    llm_group.add_argument('--llm-temperature', type=float, metavar='FLOAT',
                          help='LLM æ¸©åº¦å‚æ•° 0-1ï¼ˆé»˜è®¤: 0.1ï¼‰')
    llm_group.add_argument('--llm-max-tokens', type=int, metavar='N',
                          help='LLM æœ€å¤§ç”Ÿæˆ tokensï¼ˆé»˜è®¤: 3000ï¼‰')

    # æ–‡æ¡£å¤„ç†é…ç½®
    doc_group = parser.add_argument_group('æ–‡æ¡£å¤„ç†é…ç½®')
    doc_group.add_argument('--splitter-type', type=str, metavar='TYPE',
                          choices=['token', 'semantic', 'sentence'],
                          help='åˆ†å—ç­–ç•¥: token/semantic/sentenceï¼ˆé»˜è®¤: tokenï¼‰')
    doc_group.add_argument('--chunk-size', type=int, metavar='N',
                          help='æ–‡æ¡£åˆ†å—å¤§å°ï¼ˆé»˜è®¤: 512ï¼‰')
    doc_group.add_argument('--chunk-overlap', type=int, metavar='N',
                          help='æ–‡æ¡£åˆ†å—é‡å å¤§å°ï¼ˆé»˜è®¤: 50ï¼‰')
    doc_group.add_argument('--separator', type=str, metavar='STR',
                          help='åˆ†å—åˆ†éš”ç¬¦ï¼ˆé»˜è®¤: \\n\\nï¼‰')
    doc_group.add_argument('--semantic-breakpoint-threshold', type=float, metavar='FLOAT',
                          help='è¯­ä¹‰æ–­ç‚¹é˜ˆå€¼ 0-1ï¼ˆé»˜è®¤: 0.5 â†’ 50%%ï¼Œå€¼è¶Šé«˜è¶Šä¿å®ˆï¼Œä»…semanticæ¨¡å¼ï¼‰')
    doc_group.add_argument('--semantic-buffer-size', type=int, metavar='N',
                          help='è¯­ä¹‰ç¼“å†²åŒºå¤§å°ï¼ˆé»˜è®¤: 1ï¼Œä»…semanticæ¨¡å¼ï¼‰')
    doc_group.add_argument('--aggregate-small-chunks', action='store_true',
                          help='èšåˆJSONæ–‡ä»¶å†…çš„æ‰€æœ‰ç‰‡æ®µä¸ºä¸€ä¸ªDocumentï¼ˆé»˜è®¤: falseï¼‰')

    # å‘é‡å­˜å‚¨é…ç½®
    vector_group = parser.add_argument_group('å‘é‡å­˜å‚¨é…ç½®')
    vector_group.add_argument('--vector-store-type', type=str, metavar='TYPE',
                             help='å‘é‡å­˜å‚¨ç±»å‹ï¼ˆé»˜è®¤: chromaï¼‰')
    vector_group.add_argument('--persist-directory', type=str, metavar='PATH',
                             help='å‘é‡æ•°æ®åº“æŒä¹…åŒ–ç›®å½•')
    vector_group.add_argument('--collection-name', type=str, metavar='NAME',
                             help='é›†åˆåç§°ï¼ˆé»˜è®¤: des_literature_v1ï¼‰')
    vector_group.add_argument('--distance-metric', type=str, metavar='METRIC',
                             choices=['cosine', 'l2', 'ip'],
                             help='è·ç¦»åº¦é‡: cosine/l2/ipï¼ˆé»˜è®¤: cosineï¼‰')

    args = parser.parse_args()

    # ============================================================
    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–åˆ° SETTINGS
    # ============================================================
    overrides_applied = []

    # æ£€ç´¢é…ç½®
    if args.similarity_top_k is not None:
        SETTINGS.retrieval.similarity_top_k = args.similarity_top_k
        overrides_applied.append(f"retrieval.similarity_top_k = {args.similarity_top_k}")

    if args.rerank_top_n is not None:
        SETTINGS.retrieval.rerank_top_n = args.rerank_top_n
        overrides_applied.append(f"retrieval.rerank_top_n = {args.rerank_top_n}")

    if args.similarity_threshold is not None:
        SETTINGS.retrieval.similarity_threshold = args.similarity_threshold
        overrides_applied.append(f"retrieval.similarity_threshold = {args.similarity_threshold}")

    if args.rerank_threshold is not None:
        SETTINGS.retrieval.rerank_threshold = args.rerank_threshold
        overrides_applied.append(f"retrieval.rerank_threshold = {args.rerank_threshold}")

    # Reranker é…ç½®
    if args.no_rerank:
        SETTINGS.reranker.enabled = False
        overrides_applied.append(f"reranker.enabled = False")

    # ç¼“å­˜é…ç½®
    if args.no_cache:
        SETTINGS.cache.enabled = False
        overrides_applied.append(f"cache.enabled = False")

    # LLM é…ç½®
    if args.llm_model is not None:
        SETTINGS.llm.model = args.llm_model
        overrides_applied.append(f"llm.model = {args.llm_model}")

    if args.llm_temperature is not None:
        SETTINGS.llm.temperature = args.llm_temperature
        overrides_applied.append(f"llm.temperature = {args.llm_temperature}")

    if args.llm_max_tokens is not None:
        SETTINGS.llm.max_tokens = args.llm_max_tokens
        overrides_applied.append(f"llm.max_tokens = {args.llm_max_tokens}")

    # æ–‡æ¡£å¤„ç†é…ç½®
    if args.splitter_type is not None:
        SETTINGS.document_processing.splitter_type = args.splitter_type
        overrides_applied.append(f"document_processing.splitter_type = {args.splitter_type}")

    if args.chunk_size is not None:
        SETTINGS.document_processing.chunk_size = args.chunk_size
        overrides_applied.append(f"document_processing.chunk_size = {args.chunk_size}")

    if args.chunk_overlap is not None:
        SETTINGS.document_processing.chunk_overlap = args.chunk_overlap
        overrides_applied.append(f"document_processing.chunk_overlap = {args.chunk_overlap}")

    if args.separator is not None:
        SETTINGS.document_processing.separator = args.separator
        overrides_applied.append(f"document_processing.separator = {args.separator}")

    if args.semantic_breakpoint_threshold is not None:
        SETTINGS.document_processing.semantic_breakpoint_threshold = args.semantic_breakpoint_threshold
        overrides_applied.append(f"document_processing.semantic_breakpoint_threshold = {args.semantic_breakpoint_threshold}")

    if args.semantic_buffer_size is not None:
        SETTINGS.document_processing.semantic_buffer_size = args.semantic_buffer_size
        overrides_applied.append(f"document_processing.semantic_buffer_size = {args.semantic_buffer_size}")

    if args.aggregate_small_chunks:
        SETTINGS.document_processing.aggregate_small_chunks = True
        overrides_applied.append(f"document_processing.aggregate_small_chunks = True")

    # å‘é‡å­˜å‚¨é…ç½®
    if args.vector_store_type is not None:
        SETTINGS.vector_store.type = args.vector_store_type
        overrides_applied.append(f"vector_store.type = {args.vector_store_type}")

    if args.persist_directory is not None:
        SETTINGS.vector_store.persist_directory = args.persist_directory
        overrides_applied.append(f"vector_store.persist_directory = {args.persist_directory}")

    if args.collection_name is not None:
        SETTINGS.vector_store.collection_name = args.collection_name
        overrides_applied.append(f"vector_store.collection_name = {args.collection_name}")

    if args.distance_metric is not None:
        SETTINGS.vector_store.distance_metric = args.distance_metric
        overrides_applied.append(f"vector_store.distance_metric = {args.distance_metric}")

    print_section("LargeRAG æ€§èƒ½æµ‹è¯• - 10ç¯‡æ–‡çŒ® + 10ä¸ªé—®é¢˜")

    # æ˜¾ç¤ºå‚æ•°è¦†ç›–ä¿¡æ¯
    if overrides_applied:
        print("\nâš™ï¸  æ£€æµ‹åˆ°å‘½ä»¤è¡Œå‚æ•°è¦†ç›–:")
        for override in overrides_applied:
            print(f"  âœ“ {override}")
        print()

    # ============================================================
    # 1. è®¾ç½®æµ‹è¯•å‚æ•°
    # ============================================================
    print_section("æ­¥éª¤ 1: åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ")

    # æµ‹è¯•æ•°æ®è·¯å¾„
    test_data_dir = Path(__file__).parent.parent.parent / "data" / "rag_performance_test"
    question_file = test_data_dir / "question.txt"

    # ä½¿ç”¨é…ç½®ä¸­çš„ collection åç§°ï¼ˆå¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–ï¼‰
    # å¦‚æœç”¨æˆ·æœªæŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤å€¼ "rag_perf_test_10papers"
    if not args.collection_name:
        # ç”¨æˆ·æœªé€šè¿‡å‘½ä»¤è¡ŒæŒ‡å®šï¼Œä½¿ç”¨æµ‹è¯•ä¸“ç”¨çš„ collection åç§°
        SETTINGS.vector_store.collection_name = "rag_perf_test_10papers"
    collection_name = SETTINGS.vector_store.collection_name

    print(f"\næµ‹è¯•æ•°æ®ç›®å½•: {test_data_dir}")
    print(f"é—®é¢˜æ–‡ä»¶: {question_file}")
    print(f"Collection åç§°: {collection_name}")

    # æ£€æŸ¥æµ‹è¯•æ•°æ®æ˜¯å¦å­˜åœ¨
    if not test_data_dir.exists():
        print(f"\nâœ— é”™è¯¯: æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {test_data_dir}")
        return False

    if not question_file.exists():
        print(f"\nâœ— é”™è¯¯: é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {question_file}")
        return False

    # ç»Ÿè®¡æ–‡çŒ®æ•°é‡
    literature_folders = [d for d in test_data_dir.iterdir() if d.is_dir()]
    print(f"\nâœ“ æ£€æµ‹åˆ° {len(literature_folders)} ä¸ªæ–‡çŒ®æ–‡ä»¶å¤¹")

    # ============================================================
    # 2. åˆå§‹åŒ– LargeRAGï¼ˆä½¿ç”¨è‡ªå®šä¹‰ collectionï¼‰
    # ============================================================
    print_section("æ­¥éª¤ 2: åˆå§‹åŒ– LargeRAG")

    print(f"\nä½¿ç”¨è‡ªå®šä¹‰ collection: {collection_name}")
    print("(è¿™æ ·ä¸ä¼šå½±å“å…¶ä»–å·²æœ‰çš„ç´¢å¼•)")

    start_time = time.time()
    rag = LargeRAG(collection_name=collection_name)
    init_time = time.time() - start_time

    print(f"\nâœ“ LargeRAG åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {init_time:.2f}ç§’)")

    # è·å–å½“å‰é…ç½®å‚æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    retrieval_top_k = SETTINGS.retrieval.rerank_top_n  # æœ€ç»ˆè¿”å›ç»™ç”¨æˆ·çš„æ–‡æ¡£æ•°
    print(f"\nå½“å‰é…ç½®å‚æ•°:")
    print(f"  - å‘é‡æ£€ç´¢å¬å›æ•°: {SETTINGS.retrieval.similarity_top_k}")
    print(f"  - Rerankerè¿”å›æ•°: {SETTINGS.retrieval.rerank_top_n}")
    print(f"  - Rerankerå¯ç”¨:   {SETTINGS.reranker.enabled}")
    print(f"  - LLMæ¨¡å‹:        {SETTINGS.llm.model}")
    print(f"  - æ¸©åº¦:           {SETTINGS.llm.temperature}")
    print(f"  - æœ€å¤§tokens:     {SETTINGS.llm.max_tokens}")

    # ============================================================
    # 3. æ„å»ºç´¢å¼•ï¼ˆæˆ–åŠ è½½å·²æœ‰ç´¢å¼•ï¼‰
    # ============================================================
    print_section("æ­¥éª¤ 3: æ„å»º/åŠ è½½ç´¢å¼•")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•
    need_rebuild = args.rebuild  # ç”¨æˆ·æ˜ç¡®è¦æ±‚é‡å»º

    if not need_rebuild and rag.query_engine is not None:
        # æœ‰ç´¢å¼•ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç©º
        stats_temp = rag.get_stats()
        index_count = stats_temp['index_stats'].get('document_count', 0)
        if index_count == 0:
            print("\nâš ï¸  æ£€æµ‹åˆ°ç´¢å¼•ä¸ºç©ºï¼ˆå¯èƒ½ä¹‹å‰æ„å»ºå¤±è´¥ï¼‰ï¼Œå°†å¼ºåˆ¶é‡å»º...")
            need_rebuild = True
        else:
            print(f"\nâœ“ æ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼ˆ{index_count} ä¸ªèŠ‚ç‚¹ï¼‰ï¼Œè·³è¿‡æ„å»ºæ­¥éª¤")
            print("  æç¤º: ä½¿ç”¨ --rebuild å‚æ•°å¯å¼ºåˆ¶é‡å»ºç´¢å¼•")

    if need_rebuild or rag.query_engine is None:
        if need_rebuild:
            print("\nğŸ”„ å¼ºåˆ¶é‡å»ºç´¢å¼•...")
        else:
            print("\næœªæ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼Œå¼€å§‹æ„å»º...")

        print(f"æ–‡çŒ®æ•°é‡: {len(literature_folders)}")

        start_time = time.time()
        success = rag.index_from_folders(str(test_data_dir))
        index_time = time.time() - start_time

        if not success:
            print("\nâœ— ç´¢å¼•æ„å»ºå¤±è´¥")
            return False

        print(f"\nâœ“ ç´¢å¼•æ„å»ºæˆåŠŸ (è€—æ—¶: {index_time:.2f}ç§’ / {index_time/60:.2f}åˆ†é’Ÿ)")

    # æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
    stats = rag.get_stats()
    index_stats = stats['index_stats']
    doc_stats = stats['doc_processing_stats']

    print_subsection("ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")
    print(f"  Collection: {index_stats.get('collection_name', 'N/A')}")
    print(f"  ç´¢å¼•èŠ‚ç‚¹æ•°: {index_stats.get('document_count', 0)}")
    print(f"  å¤„ç†æ–‡æ¡£æ•°: {doc_stats.get('processed', 0)}")

    # ============================================================
    # 4. è¯»å–æµ‹è¯•é—®é¢˜
    # ============================================================
    print_section("æ­¥éª¤ 4: è¯»å–æµ‹è¯•é—®é¢˜")

    with open(question_file, 'r', encoding='utf-8') as f:
        questions = [line.strip() for line in f.readlines() if line.strip()]

    print(f"\nâœ“ è¯»å–åˆ° {len(questions)} ä¸ªé—®é¢˜\n")

    for i, q in enumerate(questions, 1):
        print(f"  Q{i}: {q}")

    # ============================================================
    # 5. æ‰§è¡Œæµ‹è¯• - å¯¹æ¯ä¸ªé—®é¢˜è¿›è¡ŒæŸ¥è¯¢
    # ============================================================
    print_section("æ­¥éª¤ 5: æ‰§è¡Œæ€§èƒ½æµ‹è¯•")

    results = []
    total_query_time = 0
    total_retrieval_time = 0

    print("\nå¼€å§‹æµ‹è¯•...\n")

    for i, question in enumerate(questions, 1):
        print_subsection(f"é—®é¢˜ {i}/{len(questions)}")
        print(f"é—®é¢˜: {question}\n")

        # 5.1 æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£ï¼ˆä¸ä½¿ç”¨LLMï¼‰
        print("  [1/2] æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£...")
        start_time = time.time()
        similar_docs = rag.get_similar_docs(question, top_k=retrieval_top_k)
        retrieval_time = time.time() - start_time
        total_retrieval_time += retrieval_time

        print(f"  âœ“ æ£€ç´¢å®Œæˆ (è€—æ—¶: {retrieval_time:.2f}ç§’)")
        print(f"  æ£€ç´¢åˆ° {len(similar_docs)} ä¸ªç›¸å…³æ–‡æ¡£")

        # æ˜¾ç¤ºæ£€ç´¢çš„æ–‡æ¡£åˆ†æ•°
        if similar_docs:
            print(f"  ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´: {similar_docs[0]['score']:.4f} ~ {similar_docs[-1]['score']:.4f}")

        # 5.2 ç”Ÿæˆå›ç­”ï¼ˆä½¿ç”¨LLMï¼‰
        print("\n  [2/2] ç”Ÿæˆå›ç­”...")
        start_time = time.time()
        answer = rag.query(question)
        query_time = time.time() - start_time
        total_query_time += query_time

        print(f"  âœ“ å›ç­”ç”Ÿæˆå®Œæˆ (è€—æ—¶: {query_time:.2f}ç§’)")

        # æ˜¾ç¤ºå›ç­”ï¼ˆå‰200å­—ç¬¦ï¼‰
        answer_preview = answer[:200] + "..." if len(answer) > 200 else answer
        print(f"\n  å›ç­”:\n  {answer_preview}\n")

        # è®°å½•ç»“æœ
        result = {
            "question_id": i,
            "question": question,
            "answer": answer,
            "retrieval_time_sec": round(retrieval_time, 2),
            "query_time_sec": round(query_time, 2),
            "num_retrieved_docs": len(similar_docs),
            "similarity_scores": [round(doc['score'], 4) for doc in similar_docs],
            "top_doc_sources": [
                {
                    "doc_hash": doc['metadata'].get('doc_hash', 'N/A')[:16],
                    "page_idx": doc['metadata'].get('page_idx', 'N/A'),
                    "score": round(doc['score'], 4)
                }
                for doc in similar_docs[:3]  # åªè®°å½•å‰3ä¸ªæ–‡æ¡£æ¥æº
            ]
        }
        results.append(result)

    # ============================================================
    # 6. ç»Ÿè®¡æµ‹è¯•ç»“æœ
    # ============================================================
    print_section("æ­¥éª¤ 6: æµ‹è¯•ç»“æœç»Ÿè®¡")

    avg_retrieval_time = total_retrieval_time / len(questions)
    avg_query_time = total_query_time / len(questions)

    print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
    print(f"  æ€»é—®é¢˜æ•°:           {len(questions)}")
    print(f"  å¹³å‡æ£€ç´¢æ—¶é—´:       {avg_retrieval_time:.2f}ç§’")
    print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´:       {avg_query_time:.2f}ç§’")
    print(f"  æ€»æ£€ç´¢æ—¶é—´:         {total_retrieval_time:.2f}ç§’")
    print(f"  æ€»æŸ¥è¯¢æ—¶é—´:         {total_query_time:.2f}ç§’")

    print("\nğŸ“Š ç´¢å¼•ç»Ÿè®¡:")
    print(f"  æ–‡çŒ®æ•°é‡:           {len(literature_folders)}")
    print(f"  ç´¢å¼•èŠ‚ç‚¹æ•°:         {index_stats.get('document_count', 0)}")
    print(f"  Collection:         {collection_name}")

    # ============================================================
    # 7. ä¿å­˜æµ‹è¯•ç»“æœåˆ° JSON
    # ============================================================
    print_section("æ­¥éª¤ 7: ä¿å­˜æµ‹è¯•ç»“æœ")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent / "test_results"
    output_dir.mkdir(exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"perf_test_{timestamp}.json"

    # æ•´åˆæ‰€æœ‰ç»“æœ
    full_results = {
        "test_info": {
            "timestamp": timestamp,
            "test_data_dir": str(test_data_dir),
            "collection_name": collection_name,
            "num_literature": len(literature_folders),
            "num_questions": len(questions),
        },
        "config_parameters": asdict(SETTINGS),  # ä¿å­˜æ‰€æœ‰é…ç½®å‚æ•°
        "performance_summary": {
            "avg_retrieval_time_sec": round(avg_retrieval_time, 2),
            "avg_query_time_sec": round(avg_query_time, 2),
            "total_retrieval_time_sec": round(total_retrieval_time, 2),
            "total_query_time_sec": round(total_query_time, 2),
        },
        "index_stats": index_stats,
        "questions_and_answers": results,
    }

    # ä¿å­˜åˆ° JSON
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(full_results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # ============================================================
    # 8. å®Œæˆ
    # ============================================================
    print_section("æµ‹è¯•å®Œæˆï¼")

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å·²å®Œæˆ")
    print(f"\næµ‹è¯•ç»“æœæ–‡ä»¶: {output_file}")
    print("\nå¯ä»¥æŸ¥çœ‹ JSON æ–‡ä»¶è·å–è¯¦ç»†ç»“æœï¼ŒåŒ…æ‹¬:")
    print("  - æ¯ä¸ªé—®é¢˜çš„å®Œæ•´å›ç­”")
    print("  - æ£€ç´¢æ€§èƒ½æŒ‡æ ‡ï¼ˆæ—¶é—´ã€ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰")
    print("  - æ–‡æ¡£æ¥æºä¿¡æ¯ï¼ˆdoc_hash, page_idxï¼‰")

    print("\n" + "=" * 80 + "\n")

    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
